{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Table of Contents\n",
    "* [Submitting HITs](#Submitting-HITs)\n",
    "\t* [Building URLs for images on s3](#Building-URLs-for-images-on-s3)\n",
    "\t* [submitting HITs in groups](#submitting-HITs-in-groups)\n",
    "\t\t* [creates HITs, careful with this one](#creates-HITs,-careful-with-this-one)\n",
    "* [Reviewing latest HITs](#Reviewing-latest-HITs)\n",
    "\t* [download](#download)\n",
    "\t* [process](#process)\n",
    "\t* [clustering](#clustering)\n",
    "\t\t* [The two commands above interact with mechanical turk and can take a while](#The-two-commands-above-interact-with-mechanical-turk-and-can-take-a-while)\n",
    "* [Merging latest round of HITs into combined dataset](#Merging-latest-round-of-HITs-into-combined-dataset)\n",
    "\t* [Load previously pickled results](#Load-previously-pickled-results)\n",
    "\t* [Load prior complete dataset if not in memory](#Load-prior-complete-dataset-if-not-in-memory)\n",
    "\t* [Updating full dataset](#Updating-full-dataset)\n",
    "\t* [Working with full dataset](#Working-with-full-dataset)\n",
    "\t\t* [worker specific](#worker-specific)\n",
    "\t\t* [Reviewing full dataset](#Reviewing-full-dataset)\n",
    "\t\t* [Sanitizing results- questions marked as answers](#Sanitizing-results--questions-marked-as-answers)\n",
    "* [Worker analysis](#Worker-analysis)\n",
    "\t* [Basic worker stats](#Basic-worker-stats)\n",
    "\t\t* [HIT duration for pricing](#HIT-duration-for-pricing)\n",
    "\t* [Identifying high and low consensus workers](#Identifying-high-and-low-consensus-workers)\n",
    "\t* [Messaging workers](#Messaging-workers)\n",
    "* [HIT end-of-life](#HIT-end-of-life)\n",
    "\t* [Pickle latest results](#Pickle-latest-results)\n",
    "\t* [Pickle combined dataset](#Pickle-combined-dataset)\n",
    "\t* [Accepting and deleting HITs... careful with these](#Accepting-and-deleting-HITs...-careful-with-these)\n",
    "* [End](#End)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import itertools\n",
    "import math\n",
    "from collections import Counter, defaultdict\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.use(\"Agg\")\n",
    "import matplotlib.pylab as plt\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "%load_ext base16_mplrc\n",
    "%base16_mplrc light default\n",
    "plt.rcParams['figure.figsize'] = (16.0, 10.0)\n",
    "\n",
    "import re\n",
    "from datetime import datetime\n",
    "import dateutil.parser as dt_parse\n",
    "import pickle\n",
    "import boto\n",
    "import json\n",
    "import os\n",
    "\n",
    "from copy import deepcopy\n",
    "import boto.mturk.connection as tc\n",
    "import boto.mturk.question as tq\n",
    "from boto.mturk.qualification import PercentAssignmentsApprovedRequirement, Qualifications, Requirement\n",
    "\n",
    "from keysTkingdom import mturk_ai2\n",
    "from keysTkingdom import aws_tokes\n",
    "\n",
    "import pdfextraction.amt_boto_modules as amt_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submitting HITs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Building URLs for images on s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "turk_data_flat_dir = '/Users/schwenk/wrk/stb/ai2-vision-textbook-dataset/diagrams/turk_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "diagram_image_names = os.listdir(turk_data_flat_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def make_hit_url(image_cat, image_name, task):\n",
    "    task_urls = {\n",
    "        'loc': \"https://s3.amazonaws.com/ai2-vision-textbook-dataset/diagrams/annotation/loc/image_text_box_region_labeling.html?\",\n",
    "        'recog': \"https://s3.amazonaws.com/ai2-vision-textbook-dataset/diagrams/annotation/recog/image_text_recognition.html?\"\n",
    "        }\n",
    "    hit_url = task_urls[task] + 'category-image={},{}'.format(image_cat, image_name)\n",
    "    return hit_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "task_type = 'loc'\n",
    "hit_urls = [make_hit_url(task_type, image_name, task_type) for image_name in diagram_image_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "len(hit_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## submitting HITs in groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "## Switch between sandbox and the real world here ##\n",
    "## DON'T FORGET to change submission POST request in the client ##\n",
    "\n",
    "sandbox_host = 'mechanicalturk.sandbox.amazonaws.com' \n",
    "real_world_host = 'mechanicalturk.amazonaws.com'\n",
    "mturk = tc.MTurkConnection(\n",
    "    aws_access_key_id = aws_tokes.access_key,\n",
    "    aws_secret_access_key = aws_tokes.access_secret_key,\n",
    "    host = real_world_host,\n",
    "    debug = 1 # debug = 2 prints out all requests.\n",
    ")\n",
    "current_account_balance = mturk.get_account_balance()[0]\n",
    "print current_account_balance # a reminder of sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "static_params = {\n",
    "    'title': \"Locate Text in Science Diagrams\",\n",
    "    'description': \"Draw boxes around text in an image\",\n",
    "    'keywords': ['image', 'science', 'text', 'bounding boxes' ],\n",
    "    'frame_height': 800,\n",
    "    'amount': 0.03,\n",
    "    'duration': 3600 * 12,\n",
    "    'lifetime': 3600 * 24 * 3,\n",
    "    'max_assignments': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### creates HITs, careful with this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "images_to_submit = hit_urls[2:]\n",
    "expected_cost = len(images_to_submit) *  static_params['amount'] * static_params['max_assignments']\n",
    "if float(current_account_balance.amount) < expected_cost:\n",
    "    print('WARNING -- account balance is too low -- WARNING')\n",
    "print('expect this batch of HITs to cost: $' + str(expected_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "uncomment cell below only when ready to submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# amt_util.create_hits_from_pages(mturk, images_to_submit, static_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviewing latest HITs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "t_hit = r_hits_current_batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "t_hit.HIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "r_hits_current_batch = amt_util.get_completed_hits(mturk)\n",
    "assignment_results_current_batch = amt_util.get_assignments(mturk, r_hits_current_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "len(assignment_results_current_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "assignment_results_current_batch.items()[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "print 'current assignment statuses'\n",
    "print amt_util.get_assignment_statuses(assignment_results_current_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "submitted_assignments = defaultdict(list)\n",
    "for hitid, assignments in assignment_results_current_batch.items():\n",
    "    for assignment in assignments:\n",
    "        if assignment.AssignmentStatus == 'Submitted':\n",
    "            submitted_assignments[hitid].append(assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "len(submitted_assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "als = pd.Series([len(sas) for sas in submitted_assignments.values()])\n",
    "als.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "submitted_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "assignment_results_current_batch.values()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def process_raw_hits(assignments_by_hit):\n",
    "    mechanical_turk_results = defaultdict(list)\n",
    "    for hit_id, hit_assignments in assignments_by_hit.items():\n",
    "        for assignment in hit_assignments:\n",
    "            for answers in assignment.answers:\n",
    "                box_result = answers[2].fields[0]\n",
    "                box_json = json.loads(box_result)\n",
    "                mechanical_turk_results[hit_id].append({\n",
    "                    assignment.AssignmentId: {answers[0].fields[0]: box_json}}\n",
    "                )\n",
    "    return mechanical_turk_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "raw_hit_results_current_batch = process_raw_hits(submitted_assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "test_box = raw_hit_results_current_batch.values()[0][0].values()[0].values()[0]\n",
    "with open ('diagram_44.jpg.json', 'w') as f:\n",
    "    box_json = json.dump(test_box, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def make_results_df(raw_hit_results):\n",
    "    col_names = ['diagram', 'rectangle', 'hit_id', 'assignment_id']\n",
    "    results_df = pd.DataFrame(columns=col_names)\n",
    "    for hit_id, assignments in raw_hit_results.items():\n",
    "        for assignment in assignments:\n",
    "            for a_id, annotation in assignment.items():\n",
    "                for diagram, rectangles in annotation.items():\n",
    "                    for box in rectangles:\n",
    "                        results_df.loc[len(results_df)] = \\\n",
    "                            [diagram, box, hit_id, a_id]\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def make_consensus_df(results_df, no_consensus_flag):\n",
    "    grouped_by_page = results_df.groupby(['diagram'])\n",
    "    aggregated_df = grouped_by_page.agg(pd.DataFrame.mode)\n",
    "#     aggregated_df.drop([ 'page', 'box_id', 'worker_id'], axis=1, inplace=True)\n",
    "    aggregated_df = aggregated_df.fillna(no_consensus_flag)\n",
    "    consensus_results_df = aggregated_df.reset_index()\n",
    "    consensus_results_df.drop('level_2', axis=1, inplace=True)\n",
    "    return consensus_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "results_df = make_results_df(raw_hit_results_current_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "results_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "grouped_by_diagram = results_df.groupby(['diagram', 'assignment_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "diagram_agreement = defaultdict(list)\n",
    "for page_user, boxes in grouped_by_diagram:\n",
    "    diagram_agreement[page_user[0]].append(len(boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "agreement_series = []\n",
    "diagrams_with_turker_agreement = []\n",
    "for page, box_counts in diagram_agreement.items():\n",
    "    agreement_series.append(len(set(box_counts)))\n",
    "    if len(set(box_counts)) == 1:\n",
    "        diagrams_with_turker_agreement.append(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "pd.Series(agreement_series).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1008,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "diff_series = []\n",
    "two_turkers_agree = defaultdict(list)\n",
    "for page, box_counts in diagram_agreement.items():\n",
    "    set_list= list(set(box_counts))\n",
    "    if len(set_list) == 2:\n",
    "        off_by = abs(set_list[1] - set_list[0])\n",
    "        diff_series.append(off_by)\n",
    "        if off_by < 6:\n",
    "            two_turkers_agree[str(off_by)].append(page)\n",
    "        else:\n",
    "            two_turkers_agree['lots'].append(page)\n",
    "pd.Series(diff_series).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1029,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diff_series = []\n",
    "no_turkers_agree = defaultdict(list)\n",
    "for page, box_counts in diagram_agreement.items():\n",
    "    set_list= list(set(box_counts))\n",
    "    if len(set_list) == 3:\n",
    "        off_by = abs(set_list[1] - set_list[0])\n",
    "        diff_series.append(off_by)\n",
    "        if off_by < 6:\n",
    "            no_turkers_agree[str(off_by)].append(page)\n",
    "        else:\n",
    "            no_turkers_agree['lots'].append(page)\n",
    "        diff_series.append(max(set_list) - min(set_list))\n",
    "pd.Series(diff_series).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "(1419. + 433 + 52) / len(submitted_assignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1027,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def limit_rect(rect, max_x, max_y, border_pad = 2):\n",
    "        if rect[0][0] < 0:\n",
    "            rect[0][0] = border_pad\n",
    "        if rect[0][1] < 0:\n",
    "            rect[0][1] = border_pad\n",
    "        if rect[1][0]  > max_x:\n",
    "            rect[1][0] = max_x - border_pad\n",
    "        if rect[1][1]  > max_y:\n",
    "            rect[1][1] = max_y -border_pad\n",
    "            \n",
    "def draw_clusters(img_path, clustered_boxes, direction='rows'):\n",
    "    \n",
    "    def random_color():\n",
    "        import random\n",
    "        return random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)\n",
    "\n",
    "    image = cv2.imread(img_path)\n",
    "    max_height, max_width, channels = image.shape\n",
    "\n",
    "    for idx, cluster in enumerate(clustered_boxes):\n",
    "#         if len(cluster) < 3 or len(cluster) >3:\n",
    "#             print idx\n",
    "#             print cluster\n",
    "#             print\n",
    "#         else:\n",
    "#             continue\n",
    "        color = random_color()\n",
    "        for box in cluster:\n",
    "            limit_rect(box, max_width, max_height)\n",
    "            cv2.rectangle(image, tuple(box[0]), tuple(box[1]), color=color, thickness=2)\n",
    "#             font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "#             cv2.putText(image, str(idx) + ' : ' + str(len(cluster)), tuple(box[1]), font, 1,(0,0,0),2)\n",
    "    return image\n",
    "\n",
    "def draw_loc_clusters(diagram_locs, dest_image_dir = '/Users/schwenk/wrk/stb/check_clustering_km/', bracket=0):\n",
    "    flattened_topic_dir = '/Users/schwenk/wrk/stb/ai2-vision-textbook-dataset/diagrams/turk_data/'\n",
    "    for diagram_name, text_locs in diagram_locs.items():\n",
    "        try:\n",
    "            clustered_text_boxes = cluster_diagram_text_centers(text_locs, 3, bracket)\n",
    "            image_path = flattened_topic_dir + diagram_name\n",
    "            drawn_image = draw_clusters(image_path, clustered_text_boxes)\n",
    "            cv2.imwrite(os.path.join(dest_image_dir, diagram_name), drawn_image)\n",
    "        except OverflowError as e:\n",
    "            print diagram_name, e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1019,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import SpectralClustering\n",
    "import cv2\n",
    "import PIL.Image as Image\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "def box_area(box):\n",
    "    height = box[1][1] - box[0][1]\n",
    "    width = box[1][0] - box[0][0]\n",
    "    return height * width\n",
    "\n",
    "def compute_intersection(b1, b2):\n",
    "    dx = min(b1[1][0], b2[1][0]) - max(b1[0][0], b2[0][0])\n",
    "    dy = min(b1[1][1], b2[1][1]) - max(b1[0][1], b2[0][1])\n",
    "    if (dx >= 0) and (dy >= 0):\n",
    "        intersection_area = dx * dy\n",
    "        return intersection_area\n",
    "    else:\n",
    "        return\n",
    "\n",
    "def comp_boxes_iou(b1, b2):\n",
    "    b1 = b1.reshape(2, 2)\n",
    "    b2 = b2.reshape(2, 2)\n",
    "    b1_area = box_area(b1)\n",
    "    b2_area = box_area(b2)\n",
    "    intersection = compute_intersection(b1, b2)\n",
    "    iou = intersection / (b1_area + b2_area - intersection)\n",
    "    return iou\n",
    "\n",
    "def comp_box_center(box):\n",
    "    return [(box[1][0] + box[0][0]) / 2, (box[1][1] + box[0][1]) / 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cluster_diagram_text(text_rects, n_turkers_assigned = 3):\n",
    "    n_clusters = int(len(text_rects) / n_turkers_assigned)\n",
    "    text_clusterer = SpectralClustering(n_clusters, affinity=comp_boxes_iou, assign_labels='kmeans', eigen_solver='arpack', n_init=100)\n",
    "    box_array = np.array(text_rects)\n",
    "    box_array = np.array(text_rects)\n",
    "    box_array_flattened = box_array.reshape(box_array.shape[0], 4)\n",
    "    box_array_flattened = box_array_flattened.astype(np.float64)\n",
    "    cluster_assignments = text_clusterer.fit_predict(box_array_flattened)\n",
    "    clustered_boxes = [box_array[cluster_assignments == cluster_n].tolist() for cluster_n in range(n_clusters)]\n",
    "    return clustered_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cluster_diagram_text_centers(text_rects, n_turkers_assigned = 3, bracket=0):\n",
    "    text_centers= [comp_box_center(rect) for rect in text_rects]\n",
    "    remainder = len(text_centers) % n_turkers_assigned\n",
    "    if not remainder:\n",
    "        n_clusters = int(len(text_centers) / n_turkers_assigned)\n",
    "    else:\n",
    "        if bracket != 'lots':\n",
    "            bracket_n = int(bracket)\n",
    "        else:\n",
    "            bracket_n = 7\n",
    "        n_clusters = len(text_centers) // n_turkers_assigned + bracket\n",
    "    text_clusterer = KMeans(n_clusters)\n",
    "    box_array = np.array(text_centers)\n",
    "    cluster_assignments = text_clusterer.fit_predict(box_array)\n",
    "    clustered_boxes = [np.array(text_rects)[cluster_assignments == cluster_n].tolist() for cluster_n in range(n_clusters)]\n",
    "    return clustered_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_df_agreement = results_df[results_df['diagram'].isin(diagrams_with_turker_agreement)]\n",
    "\n",
    "grouped_by_diagram = results_df_agreement.groupby('diagram')\n",
    "diagram_locs = defaultdict(list)\n",
    "for diagram_name, boxes in grouped_by_diagram:\n",
    "    diagram_locs[diagram_name].extend(boxes['rectangle'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "draw_loc_clusters(diagram_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1028,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for bracket, diagrams_in_bracket in two_turkers_agree.items():\n",
    "    out_dir = './two_turkers_agree_' + bracket \n",
    "    if not os.path.exists(out_dir):\n",
    "        os.mkdir(out_dir)\n",
    "    results_df_two_turkers_agree = results_df[results_df['diagram'].isin(diagrams_in_bracket)]\n",
    "    grouped_by_diagram = results_df_two_turkers_agree.groupby('diagram')\n",
    "    diagram_locs_almost = defaultdict(list)\n",
    "    for diagram_name, boxes in grouped_by_diagram:\n",
    "        diagram_locs_almost[diagram_name].extend(boxes['rectangle'].values)\n",
    "    draw_loc_clusters(diagram_locs_almost, out_dir, bracket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1030,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for bracket, diagrams_in_bracket in no_turkers_agree.items():\n",
    "    out_dir = './no_turkers_agree_' + bracket \n",
    "    if not os.path.exists(out_dir):\n",
    "        os.mkdir(out_dir)\n",
    "    results_df_two_turkers_agree = results_df[results_df['diagram'].isin(diagrams_in_bracket)]\n",
    "    grouped_by_diagram = results_df_two_turkers_agree.groupby('diagram')\n",
    "    diagram_locs_almost = defaultdict(list)\n",
    "    for diagram_name, boxes in grouped_by_diagram:\n",
    "        diagram_locs_almost[diagram_name].extend(boxes['rectangle'].values)\n",
    "    draw_loc_clusters(diagram_locs_almost, out_dir, bracket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "draw_loc_clusters(diagram_locs_almost, '/Users/schwenk/wrk/stb/check_clustering_km_almost_agree/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## single test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "problem_name = 'aquifers_6523.png'\n",
    "problem = diagram_locs_almost[problem_name]\n",
    "\n",
    "image_path = flattened_topic_dir + problem_name\n",
    "clustered_text_boxes_centers = cluster_diagram_text_centers(problem)\n",
    "\n",
    "drawn_image = draw_clusters(image_path, clustered_text_boxes_centers)\n",
    "Image.fromarray(drawn_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "[clust for clust in clustered_text_boxes_centers if len(clust) != 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### The two commands above interact with mechanical turk and can take a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "results_df_current_batch = amt_util.make_results_df(raw_hit_results_current_batch)\n",
    "consensus_results_df_current_batch = amt_util.make_consensus_df(results_df_current_batch, 'No Consensus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "no_consensus_hits = consensus_results_df_current_batch[consensus_results_df_current_batch['category'] == 'No Consensus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "flaw_rate = len(no_consensus_hits) / len(consensus_results_df_current_batch)\n",
    "print 'text boxes without consensus comprise ' + '{0:0.2f}% '.format(flaw_rate * 100) + 'of the total'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "amt_util.write_results_df(consensus_results_df_current_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# all pages from the latest batch\n",
    "pages_to_review =pd.unique(consensus_results_df_current_batch['page'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# all pages from the latest batch with a no-consensus box\n",
    "pages_to_review =pd.unique(no_consensus_hits['page'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "sampling_rate = 1\n",
    "sample_size = int(len(pages_to_review) * sampling_rate)\n",
    "sampled_pages_to_review = list(np.random.choice(pages_to_review, size= sample_size, replace=False))\n",
    "print 'sampling ' + str(sample_size) + ' pages out of ' + str(len(pages_to_review))\n",
    "to_review = ['start_seq'] + sampled_pages_to_review\n",
    "\n",
    "amt_util.review_results(to_review)\n",
    "print 'posting to review tool, navigate to http://localhost:8080/ to see the sampled consensus results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "amt_util.count_pages_with_cat(combined_consensus_df, 'Question')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "# all pages from the latest batch with a no-consensus box\n",
    "suspect_subset = results_df_current_batch[results_df_current_batch['worker_id'].isin(suspect_workers[:5])]\n",
    "amt_util.write_results_df(suspect_subset)\n",
    "pages_to_review = pd.unique(suspect_subset['page'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging latest round of HITs into combined dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load previously pickled results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "batch_number = 7\n",
    "\n",
    "with open('./store_hit_results_metadata/group_' + str(batch_number) + '/hit_info.pkl') as f:\n",
    "    r_hits_previous_batch = pickle.load(f)\n",
    "    \n",
    "with open('./store_hit_results_metadata/group_' + str(batch_number) + '/assignment_info.pkl') as f:\n",
    "    assignment_results_previous_batch = pickle.load(f)\n",
    "    \n",
    "# with open('./store_hit_results_metadata/group_' + str(batch_number) + '/raw_res.pkl') as f:\n",
    "#     raw_hit_results_previous_batch = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# combined_results_batch = pd.read_pickle(data_pickled_dir + 'complete_df.pkl')\n",
    "# combined_consensus_batch = pd.read_pickle(data_pickled_dir + 'consensus_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "missing_hits = set(assignment_results_previous_batch.keys()).difference(assignment_results_current_batch.keys())\n",
    "missing_hits_assignments = {k: v for k, v in assignment_results_previous_batch.items() if k in missing_hits}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load prior complete dataset if not in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "data_pickled_dir = './store_hit_results_metadata/group_latest_combined/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "combined_results_df = pd.read_pickle(data_pickled_dir + 'complete_df.pkl')\n",
    "combined_consensus_df = pd.read_pickle(data_pickled_dir + 'consensus_df.pkl')\n",
    "combined_consensus_with_workerid_df = pd.read_pickle(data_pickled_dir + 'consensus_df_w_workers.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Updating full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "combined_results_df = combined_results_df.append(results_df_previous_batch)\n",
    "combined_consensus_df = combined_consensus_df.append(consensus_prev)\n",
    "combined_consensus_with_workerid_df = combined_consensus_with_workerid_df.append(consensus_prevww)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "no_consensus_hits = combined_consensus_df[combined_consensus_df['category'] == 'No Consensus']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Working with full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### worker specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "flaw_rate = len(no_consensus_hits) / len(combined_consensus_df)\n",
    "print 'text boxes without consensus are ' + '{0:0.2f}% '.format(flaw_rate * 100) + 'of the total'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "workers_to_qualify = worker_quality_df[worker_quality_df['submitted'] > 100].sort_values('flaw_ratio', ascending= True).head(25).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "workers_to_qualify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "bad_and_prolific_workers[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "workers who contacted me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "wrote_me = ['A3T8FDBJQV81FN',\n",
    "'A3UUH3632AI3ZX',\n",
    "'A2QVMCGDLTWV9',\n",
    "'A356GXVAYWN0DV',\n",
    "'A2V4PRG5UBNIX0',\n",
    "'A333VJ2K6O6R79']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "workers_to_ban = bad_and_prolific_workers[:5].index.tolist()\n",
    "set(bad_and_prolific_workers.index).intersection(set(wrote_me))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "workers_to_ban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "combined_consensus_with_workerid_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "After looking through the top few offenders, it's clear that \n",
    "\n",
    "1. the very worst intentionally submitted many blank pages\n",
    "\n",
    "2. the rest didn't read the directions very closely\n",
    "\n",
    "3. I'm comfortable rejecting the work of those with > 100 submissions\n",
    "\n",
    "4. I'll ban the worst 15 from future HITs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Reviewing full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "amt_util.write_results_df(combined_consensus_df, local_result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# all pages from the complete\n",
    "pages_to_review =pd.unique(combined_consensus_df['page'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "combined_consensus_df[combined_consensus_df['category'] == 'Question'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "pages_to_review =pd.unique(combined_consensus_df[combined_consensus_df['category'] == 'Question']['page'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# all pages from the complete dataset with a no-consensus box\n",
    "# pages_to_review =pd.unique(no_consensus_hits['page'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "sampling_rate = 0.30\n",
    "sample_size = int(len(pages_to_review) * sampling_rate)\n",
    "sampled_pages_to_review = list(np.random.choice(pages_to_review, size= sample_size, replace=False))\n",
    "print 'sampling ' + str(sample_size) + ' pages out of ' + str(len(pages_to_review))\n",
    "to_review = ['start_seq'] + sampled_pages_to_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "overmerged_dir = 'labeled-annotations/'\n",
    "unmerged_dir = 'annotations_ws/'\n",
    "lessmerged_dir = 'lessmerged-annotations/'\n",
    "remerged_annotations  = 'test-remerged-annotations/'\n",
    "anno_dir = lessmerged_dir\n",
    "amt_util.review_results(to_review, anno_dir)\n",
    "print 'posting to review tool, navigate to http://localhost:8080/ to see the sampled consensus results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# %%capture \n",
    "# # all pages from the latest batch with a no-consensus box\n",
    "\n",
    "# # suspect_subset = combined_results_df[combined_results_df['worker_id'].isin(bad_and_prolific_to_review[10:15])]\n",
    "# suspect_subset = combined_results_df[combined_results_df['worker_id'].isin(['A3VE5OH94HYHET'])]\n",
    "# amt_util.write_results_df(suspect_subset)\n",
    "# pages_to_review = pd.unique(suspect_subset['page'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Sanitizing results- questions marked as answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "question_only_df = combined_consensus_df[combined_consensus_df['category'] == 'Question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "pages_w_questions = pd.unique(question_only_df['page'])\n",
    "len(pages_w_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "combined_df_question_pages_only = combined_consensus_df[combined_consensus_df['page'].isin(pages_w_questions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "combined_df_question_pages_only.to_pickle('pages_w_questions.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "question_pages_w_answers = pd.unique(combined_df_question_pages_only[combined_df_question_pages_only['category'] == 'Answer']['page'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "question_pages_w_answers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "incorrectly_marked_answers_df = combined_consensus_df[combined_consensus_df['page'].isin(question_pages_w_answers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "pd.unique(incorrectly_marked_answers_df['page']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "to_correct_aq_df = combined_consensus_df[combined_consensus_df['page'].isin(incorrectly_marked_answers_df['page'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "corrected_aq_df = to_correct_aq_df.replace('Answer', 'Question')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "local_result_path='./ai2-vision-turk-data/textbook-annotation-test/corrected_raw_hit_results/'\n",
    "# local_result_path='./ai2-vision-turk-data/textbook-annotation-test/corrected_unmerged/'\n",
    "\n",
    "amt_util.write_results_df(corrected_aq_df, local_result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "pages_to_review = pd.unique(corrected_aq_df['page'])\n",
    "sampling_rate = 1\n",
    "sample_size = int(len(pages_to_review) * sampling_rate)\n",
    "sampled_pages_to_review = list(np.random.choice(pages_to_review, size= sample_size, replace=False))\n",
    "print 'sampling ' + str(sample_size) + ' pages out of ' + str(len(pages_to_review))\n",
    "to_review = ['start_seq'] + sampled_pages_to_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# anno_dir = 'corrected_unmerged/'\n",
    "anno_dir = 'test-remerged-annotations/'\n",
    "\n",
    "amt_util.review_results(to_review, anno_dir)\n",
    "print 'posting to review tool, navigate to http://localhost:8080/ to see the sampled consensus results'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Worker analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Basic worker stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print 'number of unique workers:'\n",
    "pd.unique(combined_results_df['worker_id']).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "_ = combined_results_df['worker_id'].value_counts().hist(bins= 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### HIT duration for pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "task_duration_seconds = []\n",
    "for hit_id, assignments in assignment_results_current_batch.items():\n",
    "    for assignment in assignments:\n",
    "        hit_duration = dt_parse.parse(assignment.SubmitTime) - dt_parse.parse(assignment.AcceptTime)\n",
    "        task_duration_seconds.append(hit_duration.seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "task_duration_series = pd.Series(task_duration_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "_ = task_duration_series.hist(bins=30, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "winsorized_durations = [t for t in task_duration_seconds if t < 300]\n",
    "w_duration_series = pd.Series(winsorized_durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "_ = pd.Series(w_duration_series).hist(bins=60)\n",
    "plt.title('Worker task duration', fontsize=50, verticalalignment='bottom', color = b16_colors.b)\n",
    "plt.ylabel(\"Number of Workers\", fontsize=30, labelpad=10, color = b16_colors.b)\n",
    "plt.xlabel(\"Seconds Spent on HIT\", fontsize=30, labelpad=10, color = b16_colors.b)\n",
    "plt.tick_params(axis='x', which='major', labelsize=20)\n",
    "plt.tick_params(axis='y', which='major', labelsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "print 'duration mode= ' + str(w_duration_series.mode().values[0])\n",
    "print 'duration median= ' + str(w_duration_series.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Identifying high and low consensus workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "consensus_with_workerid_df_this_batch = amt_util.make_consensus_df_w_worker_id(results_df_current_batch, consensus_results_df_current_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "len(pd.unique(worker_conflicts['worker_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "worker_conflicts = combined_consensus_with_workerid_df[combined_consensus_with_workerid_df['category'] != combined_consensus_with_workerid_df['consensus_category']]\n",
    "all_worker_counts = combined_results_df['worker_id'].value_counts()\n",
    "bad_worker_counts = worker_conflicts['worker_id'].value_counts()\n",
    "worker_quality_df = pd.DataFrame([all_worker_counts, bad_worker_counts]).T\n",
    "worker_quality_df.columns=['submitted', 'incorrect']\n",
    "worker_quality_df['flaw_ratio'] = worker_quality_df['incorrect']/worker_quality_df['submitted']\n",
    "\n",
    "good_workers = worker_quality_df.sort_values('flaw_ratio', ascending= True).index.tolist()\n",
    "\n",
    "suspect_workers = worker_quality_df.sort_values('flaw_ratio', ascending= False).index.tolist()\n",
    "\n",
    "worker_quality_df.sort_values('flaw_ratio', ascending= True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I became concerned that I missed the perfect performers, but as I suspected perfect workers only did 1-2 HITs at most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "aw_set = set(all_worker_counts.index)\n",
    "bw_set = set(bad_worker_counts.index)\n",
    "flawless_workers = list(aw_set.difference(bw_set))\n",
    "all_worker_counts[all_worker_counts.index.isin(best_workers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "bad_and_prolific_workers = worker_quality_df.sort_values('flaw_ratio', ascending= False).head(25).sort_values('incorrect', ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "bad_and_prolific_to_review = list(bad_and_prolific_workers[:15].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Messaging workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "subject = \"More science book annotation HITs are available\"\n",
    "message = \"\"\"\n",
    "Hello, \n",
    "\n",
    "If you're receiving this message you were among the top performers on the first group HITs I submitted.\n",
    "I've submitted another group of HITs, with more to follow in the next few days. \n",
    "This task is slightly different from the first, so please review the new instructions before jumping in.\n",
    "\n",
    "Happy to get any feedback you might have for the new HITs.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "_ = mturk.notify_workers(good_workers[:20], subject, message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# HIT end-of-life"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Pickle latest results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#reset as needed\n",
    "# gn = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "gn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "next_group = gn + 1\n",
    "group_n = '_' + str(gn) + '/'\n",
    "\n",
    "temp_store_dir = './store_hit_results_metadata/group'\n",
    "try:\n",
    "    os.mkdir(temp_store_dir + group_n)\n",
    "except:\n",
    "    OSError\n",
    "    \n",
    "result_file_name = 'hit_info.pkl'\n",
    "assignment_file_name = 'assignment_info.pkl'\n",
    "raw_results_file_name = 'raw_res.pkl'\n",
    "complete_results_file = 'complete_df.pkl'\n",
    "consensus_results_file = 'consensus_df.pkl'\n",
    "\n",
    "amt_util.pickle_this(r_hits_current_batch, temp_store_dir + group_n + result_file_name)\n",
    "amt_util.pickle_this(assignment_results_current_batch, temp_store_dir + group_n + assignment_file_name)\n",
    "amt_util.pickle_this(raw_hit_results_current_batch, temp_store_dir + group_n + raw_results_file_name)\n",
    "results_df_current_batch.to_pickle(temp_store_dir + group_n + complete_results_file)\n",
    "consensus_results_df_current_batch.to_pickle(temp_store_dir + group_n + consensus_results_file)\n",
    "print 'saved HIT batch number ' + str(gn)\n",
    "print 'now onto batch ' +str(next_group) \n",
    "gn = next_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Pickle combined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "temp_store_dir = './store_hit_results_metadata/group'\n",
    "group_n = '_latest_combined/'\n",
    "try:\n",
    "    os.mkdir(temp_store_dir + group_n)\n",
    "except:\n",
    "    OSError\n",
    "    \n",
    "complete_results_file = 'complete_df.pkl'\n",
    "consensus_results_file = 'consensus_df.pkl'\n",
    "consensus_results_file_w_workers = 'consensus_df_w_workers.pkl'\n",
    "\n",
    "combined_results_df.to_pickle(temp_store_dir + group_n + complete_results_file)\n",
    "combined_consensus_df.to_pickle(temp_store_dir + group_n + consensus_results_file)\n",
    "combined_consensus_with_workerid_df.to_pickle(temp_store_dir + group_n + consensus_results_file_w_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Accepting and deleting HITs... careful with these"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Uncomment only when ready to accept or delete hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "reject assignments carefully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# number_rejected_assignments, number_rejected_workers = amt_util.reject_assignments(mturk, workers_to_ban, combined_consensus_with_workerid_df)\n",
    "# print 'rejecting ' + str(number_rejected_assignments) + ' assignments' + ' from ' + str(number_rejected_workers) + ' workers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "amt_util.get_assignment_statuses(assignment_results_current_batch_post_reject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# amt_util.accept_hits(mturk, assignment_results_current_batch_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# amt_util.delete_some_hits(mturk, assignment_results_current_batch_post_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# amt_util.delete_all_hits(mturk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def area_intersect_over_union(segmentImage1, segmentImage2, segmentArea1 = 0, segmentArea2 = 0):\n",
    "    areaIntersection = np.sum(segmentImage1 & segmentImage2)\n",
    "    if areaIntersection == 0:\n",
    "        return 0, 0, 0\n",
    "    if segmentArea1 == 0:\n",
    "        segmentArea1 = np.sum(segmentImage1)\n",
    "    if segmentArea2 == 0:\n",
    "        segmentArea2 = np.sum(segmentImage2)\n",
    "    areaOverlap = areaIntersection / (segmentArea1 + segmentArea2 - areaIntersection + 0.01)\n",
    "    areaSelfOverlap1 = areaIntersection / (segmentArea1 + 0.01)\n",
    "    areaSelfOverlap2 = areaIntersection / (segmentArea2 + 0.01)\n",
    "    return areaOverlap, areaSelfOverlap1, areaSelfOverlap2\n",
    "\n",
    "\n",
    "def comp_iou(raw_image, ocr_box, anno_box):\n",
    "\n",
    "    def update_img(mask, box):\n",
    "        # box\n",
    "        # some rectangle of the structure [[start_x, start_y], [end_x, end_y]\n",
    "        start_x, start_y = box[0]\n",
    "        end_x, end_y = box[1]\n",
    "        mask[start_y:end_y + 1, start_x:end_x + 1] = True\n",
    "\n",
    "    mask_a = np.zeros(raw_image.shape[0:2], dtype=np.bool)\n",
    "    mask_b = np.zeros(raw_image.shape[0:2], dtype=np.bool)\n",
    "    update_img(mask_a, ocr_box['rectangle'])\n",
    "    update_img(mask_b, anno_box['rectangle'])\n",
    "\n",
    "    areaOverlap, areaSelfOverlap1, areaSelfOverlap2 = areaIntersectOverUnion(mask_a, mask_b)\n",
    "\n",
    "    #iou = (mask == 2).sum() / (mask >= 1).sum()\n",
    "    return areaOverlap, areaSelfOverlap1, areaSelfOverlap2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "problem_name = 'continental_drift_9076.png'\n",
    "problem = diagram_locs[problem_name]\n",
    "\n",
    "\n",
    "image_path = flattened_topic_dir + problem_name\n",
    "drawn_image = draw_clusters(image_path, clustered_text_boxes_centers)\n",
    "Image.fromarray(drawn_image)\n",
    "\n",
    "[clust for clust in clustered_text_boxes_centers if len(clust) < 3]\n",
    "\n",
    "len (clustered_text_boxes)\n",
    "\n",
    "for box in clustered_text_boxes:\n",
    "    print box\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# def find_overlapping_boxes(user_boxes):\n",
    "#     for user in range(1, len(user_boxes)):\n",
    "#         for box1 in user_boxes[0]:\n",
    "#             for box2 in sorted(user_boxes[user]):\n",
    "#                 biou = comp_boxes_iou(box1, box2)\n",
    "#                 if biou > 0.5\n",
    "#                     print biou\n",
    "# #         print"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
